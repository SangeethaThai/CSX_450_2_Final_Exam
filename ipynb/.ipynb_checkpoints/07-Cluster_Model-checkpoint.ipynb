{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Model\n",
    "\n",
    "#### Features chosen\n",
    "\n",
    "**Numerical:**\n",
    "\n",
    "- GrLivArea\n",
    "- FirstFlrSF\n",
    "- YearBuilt\n",
    "- YearRemodAdd\n",
    "- GarageYeBuilt\n",
    "\n",
    "**Categorical**\n",
    " \n",
    "- Utilities=AllPub\n",
    "- Street=Pave\n",
    "- Condition2=Norm (Proximity to various conditions)\n",
    "- RoofMatl=CompShg\n",
    "- Heating=GasA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lib.visuals as vs\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run src/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_features_df = numerical_features\n",
    "\n",
    "one_hot_encoded_features = pd.get_dummies(categorical_features)\n",
    "top_10_features_df[\"Utilities_AllPub\"] = one_hot_encoded_features.Utilities_AllPub\n",
    "top_10_features_df[\"Street_Pave\"] = one_hot_encoded_features.Street_Pave\n",
    "top_10_features_df[\"Condition2_Norm \"] = one_hot_encoded_features.Condition2_Norm\n",
    "top_10_features_df[\"RoofMatl_CompShg\"] = one_hot_encoded_features.RoofMatl_CompShg\n",
    "top_10_features_df[\"Heating_GasA\"] = one_hot_encoded_features.Heating_GasA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_scale(dataframe, scaling_function):\n",
    "    numerical_df = dataframe.select_dtypes(include=[float, int])\n",
    "    print(numerical_df.columns)\n",
    "    numerical_df = scaling_function(numerical_df)\n",
    "    tmp_df = dataframe.copy()\n",
    "    tmp_df[numerical_df.columns] = numerical_df\n",
    "    return tmp_df\n",
    "\n",
    "def gelman_scale(dataframe):\n",
    "    return (dataframe - dataframe.mean())/(2*dataframe.std())\n",
    "\n",
    "def standard_scale(dataframe):\n",
    "    return (dataframe - dataframe.mean())/(dataframe.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gelman = apply_scale(top_10_features_df, gelman_scale)\n",
    "df_standard = apply_scale(top_10_features_df, standard_scale)\n",
    "df_gelman.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,9))\n",
    "for i, col in enumerate(top_10_features_df.columns):    \n",
    "    fig.add_subplot(3,10,1+i)\n",
    "    sns.distplot(df_gelman[col])\n",
    "    plt.xlim(-3,3)\n",
    "    fig.add_subplot(3,10,11+i)\n",
    "    sns.distplot(df_standard[col])\n",
    "    plt.xlim(-3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can see from the plots above that Gelman scaling makes the histogram slimmer with the points closer to the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_gelman = PCA()\n",
    "pca_standard = PCA()\n",
    "pca_gelman.fit(df_gelman)\n",
    "pca_standard.fit(df_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA using Gelman scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gelman_loading_plot = vs.FeatureLoadingsPlot(df_gelman, pca_gelman,4)\n",
    "gelman_loading_plot.display_segments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA using Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_loading_plot = vs.FeatureLoadingsPlot(df_standard, pca_standard,4)\n",
    "standard_loading_plot.display_segments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = ['Dimension 1', 'Dimension 2', 'Dimension 3', 'Dimension 4','Dimension 5', 'Dimension 6', 'Dimension 7', \n",
    "                    'Dimension 8', 'Dimension 9', 'Dimension 10']\n",
    "df_gelman_pca = pd.DataFrame(pca_gelman.transform(df_gelman))\n",
    "df_gelman_pca.columns = dims\n",
    "df_standard_pca = pd.DataFrame(pca_standard.transform(df_standard))\n",
    "df_standard_pca.columns = dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whos DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using PCA with Gelman scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gelman_pca_clusters = vs.Clusters(df_gelman_pca, [2,3,4])\n",
    "gelman_pca_clusters.cluster_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering using PCA with Standard scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_pca_clusters = vs.Clusters(df_standard_pca, [2,3,4])\n",
    "standard_pca_clusters.cluster_plots()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
